
<!doctype html>
<!-- START OF _layouts/default.html -->
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" >
		<meta content="width=device-width,initial-scale=1" name="viewport">
		<meta content="Andrew Hao's thoughts on software engineering, team leadership & product design." name="description">
		<meta content="The Sweet Spot" name="author">

		<title>TensorFlow For Tears: Part 1 &mdash; The Sweet Spot</title>

		<!-- Styles -->
		<link href="/stylesheets/main.css" rel="stylesheet">

		<!-- Google webfonts -->
    <link href="https://fonts.googleapis.com/css?family=Cousine|Suez+One|Yellowtail|Space+Mono|Alike+Angular" rel="stylesheet">

		<!-- jQuery and plugins -->
		<script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
		<script src="/js/jquery.zclip.min.js"></script>

		<!-- Syntax highlighter -->
		<link href="/stylesheets/prettify-hemisu.css" type="text/css" rel="stylesheet" />
    <script type="text/javascript" src="/js/prettify.js"></script>

    <link href="" rel="alternate" title="The Sweet Spot" type="application/atom+xml">
    


  </head>

	<body onload="prettyPrint()">
		<div class="wrap">

			<header>
        <a href="/"><div class="title">The Sweet Spot</div></a>
				<div class="subtitle">On software, engineering leadership, and anything shiny.</div>

				<div class="navi">
					<ul>
						<li><a href="/">Articles</a></li>
						<li><a href="/talks">Talks</a></li>
						<li><a href="/notes">Conference Notes</a></li>
						<li><a href="https://www.github.com/andrewhao">Github</a></li>
						<li><a href="https://twitter.com/andrewhao">Twitter</a></li>
					</ul>
				</div> <!-- // .navi -->
			</header>

				<!-- START OF _layouts/post.html -->

<!-- START OF _includes/article.html -->
<article>
	<header>
		<h1><a href="/2018/03/21/tensorflow-for-tears-part-1/">TensorFlow For Tears: Part 1</a></h1>
		<time>21 March 2018</time>
	</header>
		<div class="content">
			<h3 id="an-introduction-to-every-parents-trial-and-travails">An introduction to every parent’s trial and travails</h3>

<p>When our son was born early last year, I admit I wasn’t ready for it. Fatherhood was not the kind of thing I was ready for (and who really can ever be ready for parenthood, anyways?).</p>

<p>It so turns out that the vast majority of the first year of parenting is simply enduring the gut-wrenching cries of your little one. And cry they do - crying when they are too tired, screaming when they are too energetic, crying when they are gassy, screaming when they are bored, and crying when they just pooped.</p>

<p>The trials that Annie and I went through with our little guy was particularly difficult on us (you can ask me in person if we ever get to chat). The little guy was a prolific screamer and absolutely. hated. sleep.</p>

<p>What’s a geeky dad to do? Quantify household suffering by leveraging machine learning, of course.</p>

<p>I set out to build a system that would in the end determine how well our little guy slept through (or didn’t sleep through) the night. I started by building a system that naively parsed audio samples from his nursery, and then trained a TensorFlow model to do more accurate detection of his cries. Here’s how it worked:</p>

<h3 id="act-1-the-misery-meter">Act 1: The Misery Meter</h3>

<p>In version 1 of the system, I bought <a href="https://www.amazon.com/Kinobo-Microphone-Desktop-Recognition-Software/dp/B00IR8R7WQ">a cheap USB microphone</a> and hooked it up to a Raspberry Pi 3.</p>

<p>In it, I loaded up a script to record a 30-second audio sample, using the <code class="highlighter-rouge">arecord</code> UNIX command line tool:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">set</span> <span class="nt">-euxo</span> pipefail

<span class="nv">DIR</span><span class="o">=</span><span class="s2">"</span><span class="k">$(</span> <span class="nb">cd</span> <span class="s2">"</span><span class="k">$(</span> <span class="nb">dirname</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BASH_SOURCE</span><span class="p">[0]</span><span class="k">}</span><span class="s2">"</span> <span class="k">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> <span class="nb">pwd</span> <span class="k">)</span><span class="s2">"</span>
<span class="nv">RECORDING_FILE</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">DIR</span><span class="k">}</span><span class="s2">/recordings/sample.wav"</span>
<span class="nv">DATE</span><span class="o">=</span><span class="k">$(</span><span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span><span class="k">)</span>
<span class="nv">UPLOAD_RECORDING_FILENAME</span><span class="o">=</span><span class="k">$(</span><span class="nb">printf</span> %q <span class="s2">"</span><span class="k">${</span><span class="nv">DATE</span><span class="k">}</span><span class="s2">.wav"</span><span class="k">)</span>
arecord <span class="nt">--device</span><span class="o">=</span>hw:1,0 <span class="nt">--format</span> S16_LE <span class="nt">--rate</span> 48000 <span class="nt">-c1</span> <span class="nt">-d</span> 30 <span class="nt">--quiet</span> <span class="s2">"</span><span class="k">${</span><span class="nv">RECORDING_FILE</span><span class="k">}</span><span class="s2">"</span>
</code></pre></div></div>

<p>…then I ran the <code class="highlighter-rouge">sox</code> command-line tool to grab some simple loudness statistics out from it:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sox -V3 ${RECORDING_FILE} -n stats 2&gt;&amp;1 | grep dB
</code></pre></div></div>

<p>In case you’re curious, here’s the full output from <code class="highlighter-rouge">sox -V3 FILE -n stats</code>. Pretty nifty:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜ sox -V3 sample.wav -n stats
# ... Truncated for brevity ...

sox INFO sox: effects chain: input        48000Hz  1 channels
sox INFO sox: effects chain: stats        48000Hz  1 channels
sox INFO sox: effects chain: output       48000Hz  1 channels
DC offset   0.000017
Min level  -0.141083
Max level   0.135651
Pk lev dB     -17.01
RMS lev dB    -29.32
RMS Pk dB     -27.37
RMS Tr dB     -30.83
Crest factor    4.12
Flat factor     0.00
Pk count           2
Bit-depth      14/16
Num samples     480k
Length s      10.000
Scale max   1.000000
Window s       0.050
</code></pre></div></div>

<p>Here, we’re really only interested in <code class="highlighter-rouge">RMS dB</code>, which is the relative loudness levels within this 30-second sample. I chose to push these three stats up to a web service which I use to aggregate and graph these metrics. <code class="highlighter-rouge">RMS lev</code> is the average, <code class="highlighter-rouge">RMS Pk</code> is the peak, and <code class="highlighter-rouge">RMS Tr</code> is the trough (the floor).</p>

<p>I’m not showing the entirety of the script, but the last thing it does is parse and push the results of the analysis of this audio sample to a Web-based metrics aggregation service! In case you were wondering, I have an API service sitting between the Raspberry Pi and a time-series API supplied by <a href="https://www.keen.io">Keen.io</a>. But the main point is that now I can load up a cute JS widget that graphs these data points!</p>

<p><img src="/images/tensorflow-for-tears/audio-graph.png" alt="Audio crying graph" /></p>

<p>Now, how does one read this graph?</p>

<ul>
  <li>We can follow the peaks of the audio signal and assume that any noise over a certain dB threshold is the little dude’s screaming.</li>
  <li>We can follow the troughs of the graph and assume that if the trough jumps, then man there is some serious crying going on, since the audio floor of the soundscape has been bumped up!</li>
  <li>Or we can follow the average RMS reading and assume some combination of the two?</li>
</ul>

<p>The truth of the matter, none of the readings from the Misery Meter (so I called it) were particularly reliable indicators of “the little buddy is crying his little head off”. Sometimes, his crying was at the same volume level as other ambient noises in the house (say, when he’s playing in the other room and someone shuts a door). So it turns out that using volume as a proxy for crying is insufficient to give us reliable results.</p>

<h3 id="act-2-enter-tensorflow-next">Act 2: Enter TensorFlow… next!</h3>

<p>In my next post, I’ll discuss how I modified this script to use TensorFlow to train a model that could then be used to enhance the accuracy of little dude’s crying. Stick around, it’ll be fun!</p>

<p><a href="/2018/08/27/tensorflow-for-tears-part-2/">Read on for the next post!</a></p>

			
			
		</div>
	<footer>
		<div class="article__categories">
  Tagged under
  
  
  <a class="article__category" href="/category/tensorflow">TensorFlow</a>
  , 
  
  <a class="article__category" href="/category/parenting">Parenting</a>
  , 
  
  <a class="article__category" href="/category/machine-learning">Machine Learning</a>
  , 
  
  <a class="article__category" href="/category/audio-processing">Audio Processing</a>
  
  
</div>

	
	
	</footer>
	
</article>
<!-- END OF _includes/article.html -->


  <section class="comments">
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>


<!-- END OF _/layouts/post.html -->


			<footer>
				Copyright &copy; 2018

	The Sweet Spot


				

<script type="text/javascript">
      var disqus_shortname = 'g9labs';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://localhost:4000/2018/03/21/tensorflow-for-tears-part-1/';
        var disqus_url = 'http://localhost:4000/2018/03/21/tensorflow-for-tears-part-1/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











			</footer>

		</div> <!-- // .wrap -->
  </body>

	<script>
		$(document).ready(function() {
			// Make images center
			$('p:has(img)').css('text-align', 'center');

			// Add the image's title attribute as a caption
			$('p:has(img)').append(function () {
				return '<div class="caption">' + ($('img', this).attr('title') || "") + '</div>';
			});

			// Prettify code
			$('code').addClass('prettyprint');
			$('pre code').addClass('linenums');

			// Copy to clipboard with button
			$('pre:has(code)').prepend(function(){
				return '<div class="clip-btn">copy to clipboard</div>';
      });

			$('.clip-btn').zclip({
				path:'/js/ZeroClipboard.swf',
				copy: $(this).next('code').text(),
				afterCopy: function(){
					$(this).replaceWith('<div class="clip-btn">copied!');
					}
			});
		});
	</script>
</html>
<!-- END OF _layouts/default.html -->

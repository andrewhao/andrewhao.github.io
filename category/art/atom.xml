<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: art | The Sweet Spot]]></title>
  <link href="http://www.g9labs.com/category/art/atom.xml" rel="self"/>
  <link href="http://www.g9labs.com/"/>
  <updated>2016-06-24T11:21:00-07:00</updated>
  <id>http://www.g9labs.com/</id>
  <author>
    <name><![CDATA[Andrew Hao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[mmtss, a collaborative loop station]]></title>
    <link href="http://www.g9labs.com/2011/10/02/mmtss-a-collaborative-loop-station/"/>
    <updated>2011-10-02T03:53:45-07:00</updated>
    <id>http://www.g9labs.com/2011/10/02/mmtss-a-collaborative-loop-station</id>
    <content type="html"><![CDATA[<h2>mmtss is a loop station built for live performances.</h2>

<p>Let&rsquo;s make music together! This project simplifies a traditional loop tracking station and is designed for interactive collaborative music performances.</p>

<p>The idea: Everybody adds or modifies one &ldquo;part&rdquo; of a 32-bar loop. The user gets to play an instrument over the existing mix and record the 32-bar phrase when she or he is ready. Once the person is finished, the project selects another instrument at random for the next viewer to record.</p>

<p>It&rsquo;s an Ableton Live controller serving a Webkit view, backed by node.js on the backend and socket.io + RaphaelJS on the front. Communication is done through a LiveOSC Live plugin via sockets.</p>

<p>Displayed at the Regeneration &ldquo;We Collaborate&rdquo; art show in Oakland, CA. 9/24/2011.</p>

<h3>Screenshots</h3>

<p><img src="https://a248.e.akamai.net/assets.github.com/img/64abaefb0d10744dda42f362b6cd991522a88da4/687474703a2f2f6661726d372e7374617469632e666c69636b722e636f6d2f363136392f363138383336363537375f376261343864333864315f7a2e6a7067" alt="Practice mode" /></p>

<p>mmtss in practice/playback mode. Here the user is able to practice/mess around with the current instrument to prepare to record the next track.</p>

<p><img src="https://a248.e.akamai.net/assets.github.com/img/3f0c633b9b8d9d35970efe73f84c0f67bf68c6a8/687474703a2f2f6661726d372e7374617469632e666c69636b722e636f6d2f363132312f363138383838363131345f396436643531393937325f7a2e6a7067" alt="Cued mode" /></p>

<p>Pressing &ldquo;record&rdquo; puts the user in a wait state. They are prompted to begin recording when all the black boxes count down and disappear.</p>

<p><img src="https://a248.e.akamai.net/assets.github.com/img/650dc62a52d8ca6441eff57e697307325390caaa/687474703a2f2f6661726d372e7374617469632e666c69636b722e636f6d2f363137372f363138383336373135315f636135623738323733355f7a2e6a7067" alt="Record mode" /></p>

<p>mmtss in record mode.</p>

<p>More screenshots: <a href="http://www.flickr.com/photos/andrewhao/sets/72157627640840853/">http://www.flickr.com/photos/andrewhao/sets/72157627640840853/</a></p>

<h3>Source code</h3>

<p>Github: <a href="http://www.github.com/andrewhao/mmtss.">http://www.github.com/andrewhao/mmtss.</a></p>

<p>MIT/GPL-sourced for your coding pleasure.</p>

<h3>Installation</h3>

<ul>
<li><p>Make sure you have npm installed: <a href="http://www.npmjs.org/">http://www.npmjs.org</a></p></li>
<li><p>Copy <code>lib/LiveOSC</code> into <code>/Applications/Live x.y.z OS X/Live.app/Contents/App-Resources/MIDI\ Remote\ Scripts/</code> folder</p></li>
<li><p>Set it as your MIDI remote in the Ableton Live Preferences pane, in the &ldquo;MIDI Remote&rdquo; tab.</p></li>
</ul>


<h3>Running it</h3>

<ul>
<li><p>Open <code>Mmtss_0.als</code> as a sample Live project.</p></li>
<li><p>Install all project dependencies with <code>npm install</code> from the project root.</p></li>
<li><p>Start the Node server with <code>node app.js</code> from the root directory.</p></li>
<li><p>Open a Web browser and visit <code>localhost:3000</code></p></li>
</ul>


<h3>Modifying the sample project</h3>

<p>You can modify this project to suit your own needs. Note that there are two sets of tracks; instrument (MIDI input) tracks and loop tracks that actually store clips.</p>

<p>For <code>n</code> tracks, you can add or remove your own instruments. Just make sure that instrument at track <code>x</code> corresponds to track <code>x</code> + <code>n</code>.</p>

<h3>Credits</h3>

<ul>
<li><p>Design and architectural inspiration taken from <a href="http://github.com/vnoise/vtouch">vtouch</a>, a HTML5/Node/Canvas Ableton controller.</p></li>
<li><p>Original LiveOSC source is found at: <a href="http://monome.q3f.org/browser/trunk/LiveOSC">http://monome.q3f.org/browser/trunk/LiveOSC</a>. We use a different fork of the project at:<a href="http://github.com/vnoise/vtouch">http://github.com/vnoise/vtouch</a>.</p></li>
<li><p>Super sweet CSS3 rocker widgets courtesy of <a href="http://www.simurai.com/">Simurai</a>: <a href="http://lab.simurai.com/css/umbrui/">UmbrUI</a></p></li>
</ul>


<h3>License</h3>

<p><a href="http://www.opensource.org/licenses/mit-license.php">MIT</a> and <a href="http://www.gnu.org/copyleft/gpl.html">GPLv3</a> licensed. Go for it.</p>

<p>You will, however, need to get a license for <a href="http://www.ableton.com/live">Ableton Live</a> yourself.</p>

<h3>The handsome collaborators</h3>

<ul>
<li><p>Andrew Hao: <a href="http://www.g9labs.com/">http://www.g9labs.com</a></p></li>
<li><p>David Luoh: <a href="http://www.inkproj.com/">http://www.inkproj.com</a></p></li>
</ul>


<h3></h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[UN Declaration of Human Rights (Visualization)]]></title>
    <link href="http://www.g9labs.com/2011/03/22/un-declaration-of-human-rights-visualization/"/>
    <updated>2011-03-22T10:16:32-07:00</updated>
    <id>http://www.g9labs.com/2011/03/22/un-declaration-of-human-rights-visualization</id>
    <content type="html"><![CDATA[<p><a href="http://www.flickr.com/photos/andrewhao/5548186559/"><img src="http://farm6.static.flickr.com/5186/5548186559_70e047238c.jpg" alt="UN Declaration of Human Rights (Visualization)" /></a></p>

<p>This design was created from a Processing sketch that breaks up the preamble to the <a href="http://www.un.org/en/documents/udhr/index.shtml">UN Declaration of Human Rights</a> and connects adjacent words together with lines. More frequent word associations can be noted by darker, thicker lines.</p>

<p>The source code (albeit messy) can be found at <a href="http://www.github.com/andrewhao/freedom-sunday">www.github.com/andrewhao/freedom-sunday</a>. I&rsquo;m running the sketch in full Java mode, so be sure to compile with your Java IDE of choice (rather than the Processing IDE).</p>

<p>Inspiration taken from the designs of Harry Kao (<a href="http://www.hairycow.name">http://www.hairycow.name</a>) and Jer Thorp (<a href="http://blog.blprnt.com">http://blog.blprnt.com</a>).</p>

<p>My fellow interns and I are headed off to Cebu for 10 days to observe organizations involved in anti-trafficking efforts. More info: <a href="http://interns.regenerationweb.com">interns.regenerationweb.com</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slavery Today (Infographic)]]></title>
    <link href="http://www.g9labs.com/2011/03/14/slavery-today-infographic/"/>
    <updated>2011-03-14T16:15:14-07:00</updated>
    <id>http://www.g9labs.com/2011/03/14/slavery-today-infographic</id>
    <content type="html"><![CDATA[<p><a href="http://www.flickr.com/photos/andrewhao/5523317386/"><img src="http://farm6.static.flickr.com/5134/5523317386_1b2c6967c4.jpg" alt="Slavery Today Infographic (Freedom Sunday)" /></a><a href="http://www.flickr.com/photos/andrewhao/5522731659/"><img src="http://farm6.static.flickr.com/5092/5522731659_4bfa77761f.jpg" alt="Slavery Today Infographic (Freedom Sunday)" /></a></p>

<p>An infographic for <a href="http://www.freedomsunday.org/">Freedom Sunday</a> at <a href="http://www.regenerationweb.com">Regeneration</a>. <a href="http://www.andrewhao.com/wp-content/uploads/2011/03/Slavery-Today-Flyer.pdf">Download as PDF</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Save our souls - a Twitter art installation]]></title>
    <link href="http://www.g9labs.com/2011/02/23/save-our-souls-a-twitter-art-installation/"/>
    <updated>2011-02-23T02:51:37-08:00</updated>
    <id>http://www.g9labs.com/2011/02/23/save-our-souls-a-twitter-art-installation</id>
    <content type="html"><![CDATA[<p>Here&rsquo;s how the installation looked on the day of the art show.</p>

<p>[caption id=&ldquo;&rdquo; align=&ldquo;alignnone&rdquo; width=&ldquo;333&rdquo; caption=&ldquo;We mounted the installation on the inside of the Regeneration cafe. The Arduino lies behind the Macbook behind the monitor.&rdquo;]<a href="http://www.flickr.com/photos/andrewhao/5467033003/"><img src="http://farm6.static.flickr.com/5180/5467033003_c1c14c5dc0.jpg" alt="Installation" /></a>[/caption]</p>

<p>[caption id=&ldquo;&rdquo; align=&ldquo;alignnone&rdquo; width=&ldquo;333&rdquo; caption=&ldquo;The LEDs are mounted on breadboards suspended on fishing wire, binder clips, rubber bands, chopsticks, and a prayer.&rdquo;]<a href="http://www.flickr.com/photos/andrewhao/5471602272/"><img src="http://farm6.static.flickr.com/5296/5471602272_85203b475e.jpg" alt="Mounted LED array" /></a>[/caption]</p>

<p>[caption id=&ldquo;&rdquo; align=&ldquo;alignnone&rdquo; width=&ldquo;333&rdquo; caption=&ldquo;Finished it just in time.&rdquo;]<a href="http://www.flickr.com/photos/andrewhao/5471598060/"><img src="http://farm6.static.flickr.com/5057/5471598060_f1bb64a83f.jpg" alt="In action" /></a>[/caption]</p>

<p><a href="http://vimeo.com/20267056">Save our souls &ndash; Twitter art installation</a> from <a href="http://vimeo.com/user807863">Andrew Hao</a> on <a href="http://vimeo.com">Vimeo</a>.</p>

<blockquote><p>What are people saying about the ashes in the world today? This installation visualizes a live Twitter stream on heartache, injustice, loss, and our city and matches them up with the redemptive promises of Isaiah.</p></blockquote>

<p>Life is difficult, and redemption is something we all long for. What changes do you hope for in your life or in the world? Send a response from your Twitter account to @sos_61 and watch the installation react. If you&rsquo;d like to be kept anonymous, send your response in a DM to @sos_61.</p>

<p>&ldquo;I hope for <strong><strong>&rdquo;
&ldquo;I wish that </strong></strong>&rdquo;
&ldquo;I want to see ____&rdquo;</p>

<h3>A few notes</h3>

<ul>
<li><p>Web interface is a fullscreen Google Chrome window. <a href="http://socket.io/">socket.io</a> is the Websocket interface to the <a href="http://nodejs.org">node.js</a> backend. The slide transition is animated via a CSS3 animation, and the red overlay is a simple SVG shape plotted with the help of <a href="http://raphaeljs.com">RaphaëlJS</a>.</p></li>
<li><p>The Twitter backend is a collection of four self-updating Twitter searches, one for heartache (&ldquo;i feel lonely, sad, depressed&rdquo;), injustice (&ldquo;violence, war, oppression, justice&rdquo;), death (&ldquo;rest in peace, passed away&rdquo;), and Oakland (&ldquo;oakland&rdquo;). A blacklist filters out undesirable tweet keywords (&ldquo;justin bieber&rdquo;).</p></li>
<li><p>Additionally, the backend connects to Twitter via the <a href="http://dev.twitter.com/pages/streaming_api">Streaming API</a> and displays a special animation for users who reply via tweet to the <a href="http://www.twitter.com/sos_61">@sos_61</a> account.</p></li>
<li><p>The installation picks a tweet to display and pulses the LED array corresponding to the right tweet.</p></li>
<li><p>Communication to the Arduino happens via a python script over the Firmata protocol, using the <a href="https://github.com/lupeke/python-firmata">python-firmata</a> library. The nodejs server signals the script over a socket connection which will run the pulse animation on the correct pin.</p></li>
<li><p>I printed the graphic on an oversize printer with the good folks at <a href="http://alamedacopy.com">Alameda Copy</a>. Friendly service, fast turnaround, very reasonable prices. Ask for Joe.</p></li>
</ul>


<h3>Links</h3>

<ul>
<li><p><a href="http://www.github.com/andrewhao/isaiah-61-project">Source code on github.</a></p></li>
<li><p><a href="http://www.flickr.com/photos/andrewhao/sets/72157626107989740/">Flickr photos from the art show.</a></p></li>
<li><p><a href="http://www.flickr.com/photos/andrewhao/sets/72157625956085386/">Photos of the creation process.</a></p></li>
<li><p>Other posts on the process: <a href="http://www.g9labs.com/2011/02/01/the-making-of-sos-intro/">[1]</a>, <a href="http://www.g9labs.com/2011/02/11/update/">[2]</a>, <a href="http://www.g9labs.com/2011/02/12/currently-frustrated/">[3]</a>, <a href="http://www.g9labs.com/2011/02/15/arduino-and-python-firmata/">[4]</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently: frustrated]]></title>
    <link href="http://www.g9labs.com/2011/02/12/currently-frustrated/"/>
    <updated>2011-02-12T09:38:45-08:00</updated>
    <id>http://www.g9labs.com/2011/02/12/currently-frustrated</id>
    <content type="html"><![CDATA[<p>So I got the poster printed, and the LEDs currently show through the board pretty well. This is good:</p>

<p><a href="http://www.flickr.com/photos/andrewhao/5437339409/"><img src="http://farm5.static.flickr.com/4134/5437339409_14b14199d0.jpg" alt="Printed poster, testing the light" /></a></p>

<p>But last night I spent a good chunk of my evening and early morning hitting a lot of walls:</p>

<ul>
<li><p>I might have to throw out the idea of using the Twitter Streaming API. For the kind of searches I need to do, I just can&rsquo;t get enough granularity to use live information. Plus, I can only open one connection to the API at a time, which is not good if I need to run four listeners at a time.</p></li>
<li><p>I couldn&rsquo;t get the <a href="http://classifier.rubyforge.org/">Classifier</a> Ruby gem to work; which looked like the easiest implementation of an LSI/naive Bayes classifier out there. The next closest thing was <a href="http://code.google.com/p/nltk/">nltk</a>, and there was no way in heck I had the time to figure that out. Plus, I realized that creating a training set was a LOT more work than I thought I had. So&hellip; scratch the machine intelligence out of this. I&rsquo;m just going to manually search for specific search terms.</p></li>
<li><p>New solution: Periodically use the Search API to grab results. This allows more exact search results and gives me the ability to tweak the search terms while the demo loop is running.</p></li>
<li><p>Event-driven programming is throwing me for a loop (ha, get it?). After perusing the <a href="http://nodejs.org/docs/v0.4.0/api/">node.js docs</a> for the better part of an evening, I think I need to re-architect the code. I need to create a simple event-driven queue, which is confusing because it seems like something simple, yet support isn&rsquo;t built in. node provides so little out of the box.</p></li>
<li><p>It could be more difficult to set up a socket connection to Arduino than I thought. I may have to set up a socket connection in python with <a href="https://github.com/lupeke/python-firmata">python-firmata</a> to interface with the Arduino. Other Arduino/serial proxies report not working well with Snow Leopard.</p></li>
<li><p>I haven&rsquo;t yet thought about the Web interface.</p></li>
<li><p>I haven&rsquo;t thought about how I&rsquo;m going to hang the piece. I have some scrap wood and fishing wire, but I haven&rsquo;t thought about whether it&rsquo;s possible to hang all those LED arrays w/o some weird gravity issues.</p></li>
<li><p>Woodwork help? I need to figure out how to use a rotary saw.</p></li>
</ul>


<p>So uh, yeah, I&rsquo;m getting nowhere but at least I know what I still need to do.</p>
]]></content>
  </entry>
  
</feed>

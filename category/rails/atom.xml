<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rails | The Sweet Spot]]></title>
  <link href="http://www.g9labs.com/category/rails/atom.xml" rel="self"/>
  <link href="http://www.g9labs.com/"/>
  <updated>2016-06-24T11:21:00-07:00</updated>
  <id>http://www.g9labs.com/</id>
  <author>
    <name><![CDATA[Andrew Hao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Notes on performance tuning a Puma server]]></title>
    <link href="http://www.g9labs.com/2015/06/29/notes-on-performance-tuning-a-puma-server/"/>
    <updated>2015-06-29T11:47:00-07:00</updated>
    <id>http://www.g9labs.com/2015/06/29/notes-on-performance-tuning-a-puma-server</id>
    <content type="html"><![CDATA[<p>A couple of months ago, I was tuning a Rails app for one of our clients.
This client wanted to know how performant their app would be under load.</p>

<p>To do that, you can do several different things:</p>

<ol>
<li>Tune the thread/process balance within the VM</li>
<li>Horizontally scale with your cloud platform.</li>
</ol>


<p>This is a discussion of the former (#1):</p>

<h2>1) Set up the test</h2>

<h3>Drive with a synthetic script</h3>

<p>Our application had a synthetic load driver that would run Selenium to
execute various app tasks. This synthetic driver could be parallelized
across many notes via Rainforest QA, Sauce Labs or Browserify.</p>

<p>In our case, I only needed to run our synthetic load script on a single
node in multiple processes, which simulated enough load to anticipate
another order of magnitude of traffic.</p>

<h3>Know how to inspect the server under load.</h3>

<p>Commands you will want to know:</p>

<pre><code>$ free -m # Find the total amount of free memory on your machine
$ ps uH p &lt;pid&gt; # List out process threads
$ kill -TTIN &lt;puma_master_pid&gt; # Add a puma worker
$ kill -TTOU &lt;puma_master_pid&gt; # Remove a puma worker
$ kill -USR2 &lt;puma_master_pid&gt; # Kill the puma master &amp; workers
</code></pre>

<h2>Generating more load: use external load testing services, or plain tools.</h2>

<p>Try using <a href="http://www.flood.io">Flood.io</a> or JMeter for performance load.</p>

<p>I tried looking into the <a href="https://github.com/schneems/puma_auto_tune">puma_auto_tune</a> gem, but it required a higher level of production instrumentation than I was ready to give it.</p>

<h2>Analysis: New Relic scalability analysis</h2>

<p>New Relic gave us a scalability analysis scatter plot, plotting
throughput against average application response time. In essence, it
allows you to see spikes in response times as correlated to throughput.</p>

<h2>Process:</h2>

<p>My approach was to use the synthetic script to generate productionlike
node and ramp up the # of load actors in 5m increments. Each run would
test the following Puma process/thread balance:</p>

<p>Run #1: Single-process, multi threads.
Run #2: Multiple processes, single threaded.
Run #3: Multiple processes, multiple threads.</p>

<blockquote><h3>Aside: <em>how many</em> of these threads/processes should I be using?</h3>

<p>Note that your numbers will be different on the execution
characteristics of your app and your server environment. Tweak it for
yourself. You&rsquo;re designing an experiment.</p>

<p>If you&rsquo;re curious, our Rails app started out with 4 threads on 2
workers. We made the # of Puma workers (both min and max) environment
variables so we could tweak the variables easily without deploying.</p></blockquote>

<p>The strategy was then to look at the perf characteristics of each run in
the scatter plot. If there were any spikes in the graph with the
increase of load, then that would be noted. Even minor features like an
increase in slope would be noted &ndash; at that point, the incremental cost
of each request increases with overall system load.</p>

<h2>Results</h2>

<p>I don&rsquo;t have the New Relic data on hand to show, now, but in our case we
discovered two things:</p>

<ol>
<li>The server easily scaled from ~10 &ndash;> ~500 rpm with a virtually flat
line for all runs.</li>
<li>The app exhibited no noticeable performance differences when flipped
between uniprocess-multithreaded, multiprocess-unithreaded, and
multiprocess-multithreaded modes. Any performance gains were under a
tolerable threshold.</li>
</ol>


<p>How do we parse these results?</p>

<ul>
<li>We note that we didn&rsquo;t really push the performance threshold on this
app (it&rsquo;s not meant to be a public web site and 95% of it is behind a
login wall to a specialized group of users). Thus, if we pushed the
concurrent connections even more, we may have seen more of a pronounced
difference.</li>
<li>The <em>absence</em> of any major red flags was itself a validation. The
question we wanted answered coming into this experiment was &ldquo;how close
are we to maxing out our single-node EC2 configuration such that we will
have to begin configuring horizontal scaling?&rdquo;? The answer was: we can
safely scale further out in the near-term future, and cross the bridge
of horizontal scaling/bursting when we get there.</li>
<li>We did not have enough statistically significant differences in
performance for #threads/#processes in Puma. However, if we wanted to
truly find the optimal performance in our app, we would have turned to
tools like <a href="https://github.com/schneems/puma_auto_tune">puma_auto_tune</a> to answer those questions.</li>
</ul>


<p>Let me know in the comments if you have any questions!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker, Rails, and Docker Compose in your development workflow]]></title>
    <link href="http://www.g9labs.com/2015/03/19/docker-rails-and-docker-compose-in-your-development-workflow/"/>
    <updated>2015-03-19T13:29:00-07:00</updated>
    <id>http://www.g9labs.com/2015/03/19/docker-rails-and-docker-compose-in-your-development-workflow</id>
    <content type="html"><![CDATA[<p>(This post <a href="http://blog.carbonfive.com/2015/03/17/docker-rails-docker-compose-together-in-your-development-workflow/">originally appeared</a> on the Carbon Five blog.)</p>

<p>We&rsquo;ve been trialing the usage of Docker and <a href="https://docs.docker.com/compose/">Docker Compose</a> (previously known as <a href="http://www.fig.sh">fig</a>) on a Rails project here at Carbon Five. In the past, my personal experience with Docker had been that the promise of portable containerized apps was within reach, but the tooling and development workflow were still awkward &ndash; commands were complex, configuration and linking steps were complicated, and the overall learning curve was high.</p>

<p>My team decided to take a peek at the current landscape of Docker tools (primarily boot2docker and Docker Compose) and see how easily we could spin up a new app and integrate it into our development workflow on Mac OS X.</p>

<p>In the end, I&rsquo;ve found my experience with Docker tools to be surprisingly pleasant; the tooling easily integrates with existing Rails development workflows with only a minor amount of performance overhead. Docker Compose offers a seamless way to build containers and orchestrate their dependencies, and helps lower the learning curve to build Dockerized applications. Read on to find out how we built ours.</p>

<h2>Introduction to docker-compose (née Fig).</h2>

<p>Docker Compose acts as a wrapper around Docker &ndash; it links your containers together and provides syntactic sugar around some complex container linking commands.</p>

<p>We liked Docker Compose for its ability to coordinate and spin up your entire application and dependencies with one command. In the past, frameworks like Vagrant were easy ways to generate a standard image for your development team to use and get started on. Docker Compose offers similar benefits of decoupling the app from the host environment, but also provides the container vehicle for the app to run in all environments &ndash; that is, the container you develop in will often be the same container that you deploy to production with.</p>

<p>Docker (with the orchestration tooling provided by Compose) provides us the ability to:</p>

<ul>
<li>Upgrade versions of Ruby or Node (or whatever runtime your app requires) in production with far less infrastructure coordination than normally required.</li>
<li>Reduce the number of moving parts in the deployment process. Instead of writing complex Puppet and Capistrano deployment scripts, our deployments will now center around moving images around and starting containers.</li>
<li>Simplify developer onboarding by standardizing your team on the same machine images.</li>
</ul>


<p>In this example, we will run two Docker containers &ndash; a Rails container and a MySQL container &ndash; and rely on Compose to build, link, and run them.</p>

<h2>Installing boot2docker, Docker, and Docker Compose.</h2>

<p>Docker runs in a VirtualBox VM through an image called <code>boot2docker</code>. The reason we have to use <code>boot2docker</code> and VirtualBox is because the Mac OSX filesystem is not compatible with the type of filesystem required to support Docker. Hence, we must run our Docker containers within yet another virtual machine.</p>

<ol>
<li>Download and install <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a>.</li>
<li>Now install boot2docker and Docker Compose.</li>
</ol>


<p><code>bash
$ brew install boot2docker docker-compose
</code>
3. Initialize and start up boot2docker</p>

<p><code>bash
$ boot2docker init
$ boot2docker start
</code></p>

<ol>
<li>Configure your Docker host to point to your boot2docker image.</li>
</ol>


<p><code>bash
$ $(boot2docker shellinit)
</code></p>

<p>  You&rsquo;ll need to run this for every terminal session that invokes the <code>docker</code> or <code>docker-compose</code> command &ndash; better export this line into your <code>.zshrc</code> or <code>.bashrc</code>.</p>

<h2>Creating a Dockerfile</h2>

<p>Let&rsquo;s start by creating a Dockerfile for this app. This specifies the base dependencies for our Rails application. We will need:</p>

<ul>
<li>Ruby 2.2 &ndash; for our Rails instance</li>
<li>NodeJS and NPM &ndash; for installation of Karma, jshint, and other JS dependencies.</li>
<li>MySQL client &ndash; for ActiveRecord tasks</li>
<li>PhantomJS &ndash; for executing JS-based tests</li>
<li>vim &ndash; for inspecting and editing files within our container</li>
</ul>


<p>Create a <code>Dockerfile</code> from within your Rails app directory.</p>

<p>```
FROM ruby:2.2.0
RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejs npm nodejs-legacy mysql-client vim
RUN npm install -g phantomjs</p>

<p>RUN mkdir /myapp</p>

<p>WORKDIR /tmp
COPY Gemfile Gemfile
COPY Gemfile.lock Gemfile.lock
RUN bundle install</p>

<p>ADD . /myapp
WORKDIR /myapp
RUN RAILS_ENV=production bundle exec rake assets:precompile &mdash;trace
CMD [&ldquo;rails&rdquo;,&ldquo;server&rdquo;,&ldquo;-b&rdquo;,&ldquo;0.0.0.0&rdquo;]
```</p>

<p>Let&rsquo;s start by breaking this up line-by-line:</p>

<p><code>
FROM ruby:2.2.0
</code>
The <a href="https://docs.docker.com/reference/builder/#from"><code>FROM</code></a> directive specifies the <a href="https://registry.hub.docker.com/u/library/ruby/"><code>library/ruby</code> base image from Docker Hub</a>, and uses the <code>2.2.0</code> tag, which corresponds to the Ruby 2.2.0 runtime.</p>

<p>From here on, we are going to be executing commands that will build on this reference image.</p>

<p><code>
RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential nodejs npm nodejs-legacy mysql-client vim
RUN npm install -g phantomjs
</code></p>

<p>Each <a href="https://docs.docker.com/reference/builder/#run"><code>RUN</code></a> command builds up the image, installing specific application dependencies and setting up the environment. Here we install our app dependencies both from <code>apt</code> and <code>npm</code>.</p>

<h3>An aside on how a Docker image is built</h3>

<p>One of the core concepts in Docker is the concept of &ldquo;layers&rdquo;. Docker runs on operating systems that support layering filesystems such as <code>aufs</code> or <code>btrfs</code>. Changes to the filesystem can be thought of as atomic operations that can be rolled forward or backwards.</p>

<p>This means that Docker can effectively store its images as snapshots of each other, much like Git commits. This also has implications as to how we can build up and cache copies of the container as we go along.</p>

<p>The Dockerfile can be thought of as a series of rolling incremental changes to a base image &ndash; each command builds on top of the line before. This allows Docker to quickly rebuild changes to the reference image by understanding which lines have changed &ndash; and not rebuild the image from scratch each time.</p>

<p>Keep these concepts in mind as we talk about speeding up your Docker build in the following section.</p>

<h3>Fast Docker builds by caching your Gemfiles</h3>

<p>The following steps install the required Ruby gems for Bundler, within your app container:</p>

<p><code>
WORKDIR /tmp
COPY Gemfile Gemfile
COPY Gemfile.lock Gemfile.lock
RUN bundle install
</code></p>

<p>Note how we sneak the gems into <code>/tmp</code>, then run the <code>bundle install</code> which downloads and installs gems into Bundler&rsquo;s <code>vendor/bundle</code> directory. This is a cache hack &ndash; whereas in the past we would have kept the <code>Gemfile</code>s in with the rest of the application directory in <code>/myapp</code>.</p>

<p>Keeping Gemfiles inline with the app would have meant that the entire <code>bundle install</code> command would have been re-run on each <code>docker-compose build</code> &mdash; without any caching &mdash; due to the constant change in the code in the <code>/myapp</code> directory.</p>

<p>By separating out the Gemfiles into their own directory, we logically separate the Gemfiles, which are far less likely to change, from the app code, which are far more likely to change. This reduces the number of times we have to wait for a clean <code>bundle install</code> to complete.</p>

<p>HT: <a href="http://ilikestuffblog.com/2014/01/06/how-to-skip-bundle-install-when-deploying-a-rails-app-to-docker/">Brian Morearty: &ldquo;How to skip bundle install when deploying a Rails app to Docker&rdquo;</a></p>

<h3>Adding the app</h3>

<p>Finally, we finish our Dockerfile by adding our current app code to the working directory.</p>

<p><code>
ADD . /myapp
WORKDIR /myapp
RUN RAILS_ENV=production bundle exec rake assets:precompile --trace
CMD ["rails","server","-b","0.0.0.0"]
</code></p>

<p>This links the contents of the app directory on the host to the  <code>/myapp</code> directory within the container.</p>

<p>Note that we precompile all our assets before the container boots up &ndash; this ensures that the container is preloaded and ready to run and jives with Docker tenets that a container should be the same container that runs in development, test, and production environments.</p>

<h2>Setting up Docker Compose</h2>

<p>Now that we&rsquo;ve defined a <code>Dockerfile</code> for booting our Rails app, we turn to the Compose piece that orchestrates the linking phase between the Rails app and its dependencies &ndash; in this case, the DB.</p>

<p>A <code>docker-compose.yml</code> file automatically configures our application ecosystem. Here, it defines our Rails container and its db container:</p>

<p>```yaml
web:
  build: .
  volumes:</p>

<pre><code>- .:/myapp
</code></pre>

<p>  ports:</p>

<pre><code>- "3000:3000"
</code></pre>

<p>  links:</p>

<pre><code>- db
</code></pre>

<p>  env_file:</p>

<pre><code>- '.env.web'
</code></pre>

<p>db:
  image: library/mysql:5.6.22
  ports:</p>

<pre><code>- "13306:3306"
</code></pre>

<p>  env_file:</p>

<pre><code>- '.env.db'
</code></pre>

<p>```</p>

<p>A simple:</p>

<pre><code>$ docker-compose up
</code></pre>

<p>will spin up both the <code>web</code> and <code>db</code> instances.</p>

<p>One of the most powerful tools of using Docker Compose is the ability to abstract away the configuration of your server, no matter whether it is running as a development container on your computer, a test container on CI, or on your production Docker host.</p>

<p>The directive:</p>

<p><code>yaml
links:
  - db
</code></p>

<p>will add an entry for <code>db</code> into the Rails' container&rsquo;s <code>/etc/hosts</code>, linking the hostname to the correct container. This allows us to write our database.yml like so:</p>

<p>```yaml</p>

<h1>config/database.yml</h1>

<p>development: &amp;default
  host: db
```</p>

<p>Another important thing to note is the <code>volumes</code> configuration:</p>

<p>```yaml</p>

<h1>docker-compose.yml</h1>

<p>volumes:
  &ndash; .:/myapp
```</p>

<p>This mounts the current directory <code>.</code> on the host Mac to the <code>/myapp</code> directory in the container. This allows us to make live code changes on the host filesystem and see code changes reflected in the container.</p>

<p>Also note that we make use of Compose&rsquo;s <code>env_file</code> directive, which allows us to specify environment variables to inject into the container at runtime:</p>

<p><code>yaml
env_file:
  - '.env.web'
</code></p>

<p> A peek into <code>.env.web</code> shows:</p>

<p>```
PORT=3000
PUMA_WORKERS=1
MIN_THREADS=4
MAX_THREADS=16
SECRET_KEY_BASE=<Rails secret key>
AWS_REGION=us-west-2</p>

<h1>&hellip;</h1>

<p>```</p>

<p>Note that the <code>env_file</code> is powerful in that it allows us to swap out environment configurations when you deploy and run your containers. Perhaps your container needs separate configurations on dev than when on CI, or when deployed to staging or on production.</p>

<h2>Creating containers and booting them up.</h2>

<p>Now it&rsquo;s time to assemble the container. From within the Rails app, run:</p>

<pre><code>$ docker-compose build
</code></pre>

<p>This downloads and builds the containers that your web app and your db will live in, linking them up. You will need to re-run the <code>docker-compose build</code> command every time you change the <code>Dockerfile</code> or <code>Gemfile</code>.</p>

<h2>Running your app in containers</h2>

<p>You can bring up your Rails server and associated containers by running:</p>

<pre><code>$ docker-compose up
</code></pre>

<p>This is a combination of build, link, and start-services command for
each container. You should see output that indicates that both our <code>web</code> and <code>db</code> containers, as configured in the <code>docker-compose.yml</code> file, are booting up.</p>

<h2>Development workflow</h2>

<p>I was pleasantly surprised to discover that developing with Docker added very little overhead to the development process. In fact, most commands that you would run for Rails simply needed to be prepended with a <code>docker-compose run web</code>.</p>

<table>
<thead>
<tr>
<th>When you want to run:           </th>
<th> With Docker Compose, you would run:</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bundle install</code>                </td>
<td> <code>docker-compose run web bundle install</code></td>
</tr>
<tr>
<td><code>rails s</code>                       </td>
<td> <code>docker-compose run web rails s</code></td>
</tr>
<tr>
<td><code>rspec spec/path/to/spec.rb</code>    </td>
<td> <code>docker-compose run web rspec spec/path/to/spec.rb</code></td>
</tr>
<tr>
<td><code>RAILS_ENV=test rake db:create</code> </td>
<td> <code>docker-compose run -e RAILS_ENV=test web rake db:create</code></td>
</tr>
<tr>
<td><code>tail -f log/development.log</code>   </td>
<td> <code>docker-compose run web tail -f log/development.log</code></td>
</tr>
</tbody>
</table>


<h2>Protips</h2>

<p>Here are some nice development tricks I found useful when working with Docker:</p>

<ul>
<li>Add a <code>dockerhost</code> entry to your <code>/etc/hosts</code> file so you can visit <code>dockerhost</code> from your browser.</li>
</ul>


<p><code>bash
$ boot2docker ip
192.168.59.104
</code></p>

<p>  Then add the IP to your <code>/etc/hosts</code></p>

<p><code>
192.168.59.104  dockerhost
</code></p>

<p>  Now you can pull up your app from <code>dockerhost:3000</code>:</p>

<p>  <img src="http://i.imgur.com/5eqNJqN.png" alt="Screenshot of your URL bar" /></p>

<ul>
<li><p>Debugging containers with <code>docker exec</code></p>

<p>Sometimes you need to get inside a container to see what&rsquo;s <em>really</em> happening. Perhaps you need to test whether a port is truly open, or verify that a process is truly running. This can be accomplished by grabbing the container ID with a <code>docker ps</code>, then passing that ID into the <code>docker exec</code> command:</p></li>
</ul>


<p><code>bash
$ docker ps
CONTAINER ID        IMAGE
301fa6331388        myrailsapp_web:latest
$ docker exec -it 301fa6331388 /bin/bash
root@301fa6331388:/myapp#
</code></p>

<ul>
<li>Showing environment variables in a container with <code>docker-compose run web env</code></li>
</ul>


<p>```bash
$ docker-compose run web env
AWS_SECRET_KEY=
MAX_THREADS=16
MIN_THREADS=4
AWS_REGION=us-west-2
BUNDLE_APP_CONFIG=/usr/local/bundle
HOME=/root</p>

<h1>&hellip;</h1>

<p>```</p>

<ul>
<li><p>Running an interactive debugger (like <a href="http://pryrepl.org/">pry</a>) in your Docker container</p>

<p>It takes a little extra work to get Docker to allow interactive terminal debugging with tools like <code>byebug</code> or <code>pry</code>. Should you desire to start your web server with debugging capabilities, you will need to use the <code>--service-ports</code> flag with the <code>run</code> command.</p></li>
</ul>


<p><code>bash
$ docker-compose run --service-ports web
</code></p>

<p>  This works due to two internal implementations of <code>docker-compose run</code>:</p>

<ul>
<li><code>docker-compose run</code> creates a TTY session for your app to connect to, allowing interactive debugging. The default <code>docker-compose up</code> command does not create a TTY session.</li>
<li><p>The <code>run</code> command does not map ports to the Docker host by default. The <code>--service-ports</code> directive maps the container&rsquo;s ports to the host&rsquo;s ports, allowing you to visit the container from your web browser.</p></li>
<li><p>Use <code>slim</code> images when possible on production</p></li>
</ul>


<p>  Oftentimes, your base image will come supplied with a <code>-slim</code> variant on Docker Hub. This usually means that the image maintainer has supplied a trimmed-down version of the container for you to use with source code and build-time files stripped and removed. You can oftentimes shave a couple hundred megabytes off your resulting image &mdash; we did when we switched our <code>ruby</code> image from <code>2.2.1</code> to <code>2.2.1-slim</code>. This results in faster deployment times due to less network I/O from the registry to the deployment target.</p>

<h2>Gotchas</h2>

<ul>
<li><p>Remember that your app runs in containers &ndash; so every time you do a <code>docker-compose run</code>, remember that Compose is spinning up entirely new containers for your code <strong>but only if the containers are not up already, in which case they are linked to that (running) container</strong>.</p>

<p>This means that it&rsquo;s possible that you&rsquo;ve spun up multiple instances of your app without thinking about it &ndash; for example, you may have a <code>web</code> and <code>db</code> container already up from a <code>docker-compose up</code> command, and then in a separate terminal window you run a <code>docker-compose run web rails c</code>. That spins up <em>another</em> <code>web</code> container to execute the command, but then links that container with the pre-launched <code>db</code> container.</p></li>
<li><p>There is a small but noticeable performance penalty running through both the VirtualBox VM and docker. I&rsquo;ve generally noticed waiting a few extra seconds when starting a Rails environment. My overall experience has been that the penalty has not been large enough to be painful.</p></li>
</ul>


<h2>Try it out</h2>

<p>Give this a shot and let me know how Docker has been working for you. What have your experiences been? What are ways in which you&rsquo;ve been able to get your Docker workflow smoother? Share in the comments below.</p>

<h3>Coming up: integration with CI and deployment.</h3>

<p>In upcoming blog posts, we will investigate how to use the power of Docker Compose to test and build your containers in a CI-powered workflow, push to Docker registries, and deploy to production. Stay tuned!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ember Data, Rails, CORS, and you!]]></title>
    <link href="http://www.g9labs.com/2013/12/27/ember-data-rails-cors-and-you/"/>
    <updated>2013-12-27T16:22:00-08:00</updated>
    <id>http://www.g9labs.com/2013/12/27/ember-data-rails-cors-and-you</id>
    <content type="html"><![CDATA[<p>I&rsquo;m starting up a new personal project involving Ember-Data and Rails
(more to come). The gist of it is that it&rsquo;s a pure frontend app engine
built in Yeoman and Grunt, and designed to talk to a remote API service
built on Rails.</p>

<p>So since it&rsquo;s a remote API, I&rsquo;ve got to enable CORS, right?</p>

<h2>Install CORS via rack-cors</h2>

<p><code>ruby Gemfile.rb
gem "rack-cors", :require =&gt; "rack/cors"
</code></p>

<p>```ruby config/application.rb
config.middleware.use Rack::Cors do
  allow do</p>

<pre><code>origins "*"

resource "*",
  :headers =&gt; :any,
  :methods =&gt; [:get, :post, :put, :delete, :options, :patch]
end
</code></pre>

<p>  allow do</p>

<pre><code>origins "*"
resource "/public/*",
  :headers =&gt; :any,
  :methods =&gt; :get
</code></pre>

<p>  end
end
```</p>

<p>A very naive implementation with zero security whatsoever. Anyways.
Onward!</p>

<h2>Get Ember-Data DS.RESTAdapter talkin' CORS</h2>

<p>I saw conflicting documentation on Ember-Data and CORS &mdash; it seemed like
it should support CORS out of the box. Apparently this is not so.</p>

<p>In my ember app&rsquo;s <code>store.js</code> (or anywhere your app loads before the
application adapter is defined, do this:</p>

<p>```javascript store.js
$.ajaxSetup({
  crossDomain: true,
  xhrFields: {</p>

<pre><code>withCredentials: true
</code></pre>

<p>  }
});</p>

<p>Hendrix.Store = DS.Store.extend();
Hendrix.ApplicationAdapter = DS.RESTAdapter.extend({
  host: &ldquo;<a href="http://localhost:3000">http://localhost:3000</a>&rdquo;,
})
```</p>

<p><a href="http://api.jquery.com/jQuery.ajaxSetup/"><code>$.ajaxSetup</code></a>, though its
usage is not recommended, is designed to set global options on the
jQuery <code>ajax</code> object. It provides some information on the options you can modify.</p>

<p>Why doesn&rsquo;t Ember support this out of the box? I think it&rsquo;s because they
cannot support IE, where one must use an XDR object to support CORS.</p>

<p>I&rsquo;ve posted an <a href="http://discuss.emberjs.com/t/ember-data-and-cors/3690">Ember follow-up question in the
forums</a> for discussion.</p>

<h2>Get Rails talking JSON out of its mimetype confusion.</h2>

<p>Did you know that if you rely on the <code>Accepts:</code> header in HTTP that
Rails does not obey its ordering<code>*</code>? I was trying to figure out why my
Rails controllers were trying to render HTML instead of JSON when the
headers were:</p>

<p><code>'Accept: application/json, text/javascript, */*; q=0.01'</code></p>

<p>A <a href="https://github.com/rails/rails/issues/9940">very long winded
discussion</a> on the Rails
project reveals that, well, nobody has it figured out yet. Most modern
browsers do obey <code>Accepts:</code> specificity, but for the sake of older
browser compatibility, the best practice for browsers is still to return
HTML when <code>*/*</code> is specified.</p>

<p>What does this mean for Rails developers who want to use <code>Accepts:</code>
mimetype lists? Well, we either wait for the Rails projects to support
mimetype specificity (and for older browsers to die out), or we are
encouraged to include the format explicitly in the URI.</p>

<p>I chose to have Ember append the <code>.json</code> suffix to the URL, thanks to
this <a href="http://stackoverflow.com/questions/13648807/ds-model-url-not-working-in-ember-js">SO
post</a></p>

<p><code>``javascript store.js
Hendrix.ApplicationAdapter = DS.RESTAdapter.extend({
  host: "http://localhost:3000",
  // Force ember-data to append the</code>json` suffix
  buildURL: function(record, suffix) {</p>

<pre><code>return this._super(record, suffix) + ".json";
</code></pre>

<p>  }
})
```</p>

<p>More to come how how this app works.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Decomposing Fat Models]]></title>
    <link href="http://www.g9labs.com/2012/12/26/decomposing-fat-models/"/>
    <updated>2012-12-26T04:46:09-08:00</updated>
    <id>http://www.g9labs.com/2012/12/26/decomposing-fat-models</id>
    <content type="html"><![CDATA[<p>Heard an awesome Ruby Rogues podcast recently: <a href="http://rubyrogues.com/083-rr-decomposing-fat-models-with-bryan-helmkamp/">&ldquo;Decomposing Fat Models&rdquo;</a>.</p>

<p>Essentially, they&rsquo;re talking through Bryan Helmkamp&rsquo;s <a href="http://blog.codeclimate.com/blog/2012/10/17/7-ways-to-decompose-fat-activerecord-models/">Code Climate blog entry &ldquo;7 ways to decompose fat ActiveRecord models&rdquo;</a>, which sums up a few strategies that mainly involve extracting objects from your existing code, value, service, policy, decorator objects and the like. Give the entry a read-through, it&rsquo;s opened my eyes a lot to rethinking my architecture of my Rails models.</p>

<p>A few interesting thoughts that came up in the podcast:</p>

<ul>
<li><p>The &ldquo;Skinny Controller, Fat Model&rdquo; mantra has hurt the Rails community because we start getting these bloated AR classes. &ldquo;&lsquo;fat-&rsquo; anything is bad&rdquo; one of the hosts mentions in the blog. The smaller your models, the more manageable, readable and testable they become.</p></li>
<li><p>Rubyists don&rsquo;t like the term &ldquo;Factory&rdquo;, even though in Helmkamp&rsquo;s opinion, Ruby classes <em>are</em> factories. &ldquo;We call them "builders&rdquo;&ldquo; one of the hosts jokes.</p></li>
<li><p>The Open/Closed Principle as applied to Ruby: using delegators, decorators.</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speeding up Rspec/Cucumber feedback times without sacrificing coverage]]></title>
    <link href="http://www.g9labs.com/2012/04/27/speeding-up-rspeccucumber-feedback-times-without-sacrificing-coverage/"/>
    <updated>2012-04-27T10:27:17-07:00</updated>
    <id>http://www.g9labs.com/2012/04/27/speeding-up-rspeccucumber-feedback-times-without-sacrificing-coverage</id>
    <content type="html"><![CDATA[<iframe src="http://www.slideshare.net/slideshow/embed_code/4479466" width="512" height="421" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen>
</iframe>


<p><a href="http://www.slideshare.net/josephwilk/rocket-fuelled-cucumbers">Rocket Fuelled Cucumbers</a>
View more <a href="http://www.slideshare.net/">presentations</a> from <a href="http://www.slideshare.net/josephwilk">Joseph Wilk</a></p>

<p>One thing the Blurb devs have been discussing is how we can speed up our test feedback cycles without sacrificing coverage. There&rsquo;s some good tips (mainly Rails+Rspec/Cucumber) in the presentation such as:</p>

<ul>
<li>Don&rsquo;t run all the tests when developing (tag your tests by function)</li>
<li>Parallelize, chunk tests over machines/cores using Testjour/<a href="https://github.com/sandro/specjour">Specjour</a>, <a href="https://github.com/ngauthier/hydra">Hydra</a></li>
<li>Don&rsquo;t run all the tests at once. Tests that never fail should nightly.</li>
<li>Instead of spinning up a browser for acceptance tests, can you use a js/DOM simulator (e.g. <a href="https://github.com/thatcher/env-js">envjs</a> via <a href="https://github.com/smparkes/capybara-envjs">capybara-envjs</a>, or <a href="https://github.com/jarib/celerity">celerity</a>)</li>
</ul>

]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Rate limiting | The Sweet Spot]]></title>
  <link href="http://www.g9labs.com/category/rate-limiting/atom.xml" rel="self"/>
  <link href="http://www.g9labs.com/"/>
  <updated>2016-06-16T13:56:32-07:00</updated>
  <id>http://www.g9labs.com/</id>
  <author>
    <name><![CDATA[Andrew Hao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lossless rate limiting with RxJS]]></title>
    <link href="http://www.g9labs.com/2016/03/21/lossless-rate-limiting-with-rxjs/"/>
    <updated>2016-03-21T13:09:00-07:00</updated>
    <id>http://www.g9labs.com/2016/03/21/lossless-rate-limiting-with-rxjs</id>
    <content type="html"><![CDATA[<p>Much of RxJS involves working with
<a href="http://reactivex.io/documentation/operators/backpressure.html">backpressure</a> &ndash; how to reconcile
streams that emit/process data at different rates, without overloading
the system. Much of that model is built with lossy handling in mind &ndash; it
makes sense that when your system is under duress, that you design your
streams to degrade gracefully (e.g. drop certain events, or rate limit
them by chunking into windows, etc).</p>

<p>However, there are times when it is appropriate to have a lossless
approach to backpressure &ndash; e.g., to store every chunk of data that comes
through a stream in memory, and not drop things. These use cases may
come about when:</p>

<ul>
<li>You have a short-lived, or bounded set of data you know will come over
the pipe. You understand the bounds of the data that will ever come over
the pipe.</li>
<li>You have a processing script you want to run, which is not part of a
large system.</li>
<li>You have a honkin' large system that can handle the load.</li>
</ul>


<p>In my case, I had a script that called the Google Geocoding API for a
set of GPS coordinates. Now for a set of several hundred coordinates, I
would end up calling the API several hundred times all at once with this
naive implementation:</p>

<p><code>javascript
// address$: [ "1234 Widget Way, Promiseland, WV" ] -- [...] -- [...]
const geocoded$ = addresses$
.flatMap(address =&gt; Rx.Observable.fromPromise(callGoogleGeocodingService(address)))
// geocoded$: [ { latitude: 89.99, longitude: 90.00, ... } ] -- [...] -- [...]
</code></p>

<p>I searched all over for a lossless throttling mechanism, but all I could
find was references to RxJS&rsquo;s lossy <a href="">throttle</a> behavior.</p>

<p>Other frameworks, like <a href="https://github.com/baconjs/bacon.js/#observable-bufferingthrottle">Bacon.js&rsquo;s bufferingThrottle()</a> and <a href="http://highlandjs.org/#ratelimit">Highland.js ratelimit()</a> seemed attractive. Where was RxJS&rsquo;s equivalent?</p>

<p>Thanks to a <a href="http://stackoverflow.com/questions/34955842/rate-limiting-http-calls-made-by-rxjs">helpful StackOverflow post</a>,
I found the answer: the use of
<a href="https://github.com/Reactive-Extensions/RxJS/blob/master/doc/api/core/operators/concatmap.md">concatMap()</a>
and
<a href="https://github.com/Reactive-Extensions/RxJS/blob/master/doc/api/core/operators/delay.md">delay()</a>
forces the incoming stream to execute serially over artificial time delayed streams.</p>

<p><code>javascript
const geocoded$ = addresses$
.concatMap(address =&gt; Rx.Observable.just(address).delay(TIME_INTERVAL))
.flatMap(address =&gt; Rx.Observable.fromPromise(callGoogleGeocodingService(address)))
</code></p>

<p>Thanks to:</p>

<ul>
<li><a href="http://stackoverflow.com/questions/34955842/rate-limiting-http-calls-made-by-rxjs">http://stackoverflow.com/questions/34955842/rate-limiting-http-calls-made-by-rxjs</a></li>
<li><a href="http://stackoverflow.com/questions/30876361/rxjs-rate-limit-requests-per-second-and-concurrency?rq=1">http://stackoverflow.com/questions/30876361/rxjs-rate-limit-requests-per-second-and-concurrency?rq=1</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
